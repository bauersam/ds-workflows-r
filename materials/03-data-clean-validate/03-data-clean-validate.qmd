---
title: "Clean and Validate Data"
format:
  email:
    toc: true
    toc-location: left
    anchor-sections: true
    code-fold: true
    code-overflow: wrap
    code-summary: "Show Code"
    code-tools: true
    code-link: true
editor_options: 
  chunk_output_type: console
  canonical: true
html-table-processing: none
---

## Goals

The goals of this activity are to:

-   use a environment variable to toggle state for development and testing
-   perform data cleaning and validation to prepare data for our model
-   define thresholds for alerting in data validation and send condition-based email alerts based on those thresholds

Our conditions will send an email based on the the following:
    1.  `condition <- 1`: the size and shape of the data is not as expected; something is wrong with the input data so the processing of data is stopped and no production data is updated
    2.  `condition <- 2`: data validation complete but had warnings
    3.  `condition <- 3`: no issues


‚úèÔ∏è There will be placeholders (`____`) in the code cells below that you will need to fill in!

## Setup

```{r}
#| label: setup

library(DBI)
library(RPostgres)
library(pointblank)
library(tidyverse)
library(glue)
library(gt)
library(ferryfairy)

```

## Task 1 - Define a "condition override" so we can manually trigger a condition and see the resulting email

üîÑ Task

Use an environment variable called `CONDITION_OVERRIDE` to be used during development and testing which will:

-   prevent data from being written to the database
-   send the corresponding conditional email based on the value set

The benefit of using an environment variable is that it can be set / modified in the "Vars" pane on Connect, meaning you can test different conditions without changing the deployed code.

Our conditions are: 1. `condition <- 1`: the size and shape of the data is not as expected; something is wrong with the input data so the processing of data is stopped and no production data is updated 2. `condition <- 2`: data validation complete but had warnings 3. `condition <- 3`: no issues

### Set environment variable locally

To set this environment variable locally during development, add it to your `.Renviron` file. To do this, run the following command in your R console:

``` r
usethis::edit_r_environ("project")
```

``` {.bash filename=".Renviron"}
# file: either ~/.Renviron or .Renviron in the project root
# set condition to either 1, 2, or 3 to preview the conditional responses.
CONDITION_OVERRIDE=1
```

üí° Remember, the `.Renviron` file does not get deployed with this content, and you should not commit it to git. It is a local file that sets environment variables for your R session. You will be able to set this variable in the "Vars" pane on Connect when you deploy the report if you want to implement an override.

### Print a notification if an override is in place

This will appear in the rendered report if an override is place.

```{r}
#| label: identify test mode
#| output: asis

# set CONDITION_OVERRIDE={1|2|3} in `.Renviron` to preview the conditional responses.
if(Sys.getenv("CONDITION_OVERRIDE") %in% c(1:3)) { 
glue::glue("<h3>‚ùó‚ùó Report generated in test mode. 
Data not written to database but an email for condition {Sys.getenv('CONDITION_OVERRIDE')} is sent  ‚ùó‚ùó</h3>\n") }

```

## Task 2 - Read in raw data

üîÑ Task

Retrieve the raw data from the database for cleaning and validating.

### Connect to the database

```{r}
#| label: make database connection

# # Run this code as-is 
# con <- dbConnect(RPostgres::Postgres(), 
#                  host = Sys.getenv("CONF24_DB_HOST"), 
#                  port = "5432", 
#                  dbname = "conf23_r", 
#                  user = Sys.getenv("CONF24_DB_USER"), 
#                  password = Sys.getenv("CONF24_DB_PASSWORD"))

```

In our local development environment (Posit Workbench), we will pull the smaller data set with your own Workshop participant username as a suffix. When this notebook is published to Posit Connect, the suffix will be read as `production` thanks to the `{config}` package and we'll do this data cleaning and validation on the full production dataset.

```{r}
#| label: read in raw data

# df_suffix <- config::get("suffix")
# 
# vesseldata_raw <- dplyr::tbl(con, glue("vesseldata_raw_{df_suffix}"))
# 
# vesselhistory_raw <- dplyr::tbl(con, glue("vesselhistory_raw_{df_suffix}"))
# 
# weather_terminal_history_raw <- dplyr::tbl(con, glue("weather_terminal_history_raw_{suffix}"))

```

```{r}

library(pins)

board <- board_connect()

vesselinfo_raw <- pin_read(board, "katie.masiello/vesselinfo_raw_katiemasiello")

vesselhistory_raw <- pin_read(board, "katie.masiello/vesselhistory_raw_katiemasiello")

weather_terminal_history_raw <- pin_read(board, "katie.masiello/weather_terminal_history_raw_katiemasiello")

```

## Task 3 - Introduction to data validation

üîÑ Task

-   Use the `pointblank` package to perform data validation on a sample data frame
-   Define thresholds in data validation to be used for alerting

### Create a sample data frame for experimentation

We will toy with a simple data frame in the Workshop, then see the validation steps for our project below. Note that the code chunks in this section are set to `eval: false` so they will not be executed when we deploy this document to Posit Connect.

```{r}
#| eval: false

df <- dplyr::tibble(
    a = c(5, 7, 6, 5, NA, 7),
    b = c(6, 1, NA, 6,  0, 7),
    fruits = fruit[1:6],
    date = seq(today()-2, today()+3, 1)
  )

```

### Validatate the sample data frame

The first step in the `pointblank` workflow is to create an **agent.**

```{r}
#| label: create agent 
#| eval: false

agent <- pointblank::create_agent(____)
agent
```

On its own, the agent is not informative. It's waiting for validations to be defined and an interrogation action to be performed.

Now we define our **data validation functions**. A few have been started for you as examples. It's up to you to fill in the suggested validations or create your own. Refer to the package documentation for the validation function reference: <https://rstudio.github.io/pointblank/reference/index.html#validation-expectation-and-test-functions>

```{r}
#| label: define validations for df
#| eval: false

agent <- create_agent(df) |>
  col_vals_between(
    columns = a, 1, 9,
    na_pass = TRUE
  ) |> 
  col_vals_lt(
    columns = new_column, 12,
    preconditions = ~ . %>% dplyr::mutate(new_column = a + b)
  ) |> 
  col_vals_in_set(
    columns = fruits, c("apple", "avocado", "blueberry", "mango", "plum", "tangerine")
  ) |> 
  # Now add the following:
  # verify the numeric columns do not have NA values 
  # (hint: use `columns = c(a,b)` to apply the validation to multiple columns)
  ____ |> 
  # verify that the date is before today
  ____ |> 
  # would you like to add more?
  ____ |> 


agent

```

If we look at the output of `agent`, it shows our validation plan, but the action is yet to come when we **interrogate**.

```{r}
#| label: interrogate the df agent

agent |> interrogate()

```

Explore the validation report. Can you:

1.  Identify what fail percentage each validation had?
2.  Identify how many rows failed each validation?
3.  View the CSV extracts of failed data?

Change the parameters of your validations to trigger more failures just to see the consequence.

### Add Action Levels

Iterate on your agent created above to add action levels. Action levels behave like tags. You can decide what threshold you want to put for `notify`, `warn`, and `stop`. At a minimum, the tag will provide a visual indicator of threshold exceedance in the validation table. You can also use these tags post-interrogation to take actions.

The action levels can be set as an **integer**, representing the threshold number of failing units, or a **fraction**, representing the fraction of failing units.

Use `actions = action_levels(warn_at = ____, stop_at = ____, notify_at = ____)` to add action levels to one, some, or all of your validations and rerun the interrogation to see the output. Some samples have been provided.

```{r}
#| label: validation of df with action levels
#| eval: false

agent <- create_agent(df) |>
  col_vals_between(
    columns = a, 1, 9,
    na_pass = TRUE,
    actions = action_levels(warn_at = 0.2, stop_at = 0.3)
  ) |> 
    col_vals_lt(
  columns = new_column, 12,
    preconditions = ~ . %>% dplyr::mutate(new_column = a + b),
    label = "the sum of a+b must be than 12",
    actions = action_levels(warn_at = 0.005)
  ) |> 
  col_vals_in_set(
    columns = fruits, c("apple", "avocado", "blueberry", "mango", "plum", "tangerine"),
    label = "only serve my favorite fruits"
    # actions = ____
  ) |> 
  col_vals_not_null(
    columns = c(a,b)
    # actions = ____
  ) |> 
  col_vals_lt(
    date, today()
  ) |> 
interrogate()


agent

```

### Remove failing data from the data set

Pointblank has identified all of the rows of `df` that passed and failed validation. Now remove those that failed so the data that is passed downstream is squeaky clean.

Pointblank provides a number of [post-interrogation functions](https://rstudio.github.io/pointblank/reference/index.html#post-interrogation) to work with intel gathered from the validation. For this task, we will "sunder" the data using `pointblank::get_sundered_data()`.

> **üí° sunder** /sun¬∑der / Ààs…ôn-d…ôr / *verb* \| to split apart

```{r}
#| label: sunder data
#| eval: false

# Passed data
df_validated <- get_sundered_data(agent = ____,
                                  type = "____")

# Failed data
df_failed_validation <- get_sundered_data(agent = ____,
                                          type = "____")

```

### Post-interrogation logicals

Pointblank interrogation provides multiple layers of information about our data. We can take advantage of this with logical TRUE / FALSE statements that drive downstream tasks or effects.

-   Use `pointblank::all_passed()` to determine if all validation steps passed
-   Use `pointblank::get_agent_x_list` to determine if any warnings were set

```{r}
#| label: All validations passed?
#| eval: false

# Did all validations pass?
pointblank::____


```

A broad all passed / failed for the entire validation plan might not provide enough granularity for a downstream task. We can drill into more details about each step of the validation and the results using the agent "x_list".

First we will see what the x_list contains.

```{r}
#| label: get agent x list
#| eval: false

xlist <- pointblank::get_agent_x_list(agent)

xlist

```

The output is like a gold mine! The resulting list includes the pass / fail statistics (`$n_passed`, `$n_failed`, `$f_passed`, `$f_failed`) and what we are after -- the validations with warnings. Let's take a look.

```{r}
#| label: Any warning flags set?
#| eval: false

xlist$____

```

Extracting these basic TRUE / FALSE values can be powerful for next steps. We'll see how we can send conditional emails in the next section of the workshop.


## Task 4 - Validate raw production data schema

üîÑ Task

All of our downstream tasks depend on our raw data coming in with the expected columns and schema. We could impose errors downstream if we process errant data.

-   Use pointblank to validate the weather and vessel history raw data has the expected columns and schema.
-   If the data is not as expected, stop processing and set a data integrity alert.
-   If the data is as expected, proceed with cleaning, transforming, and preparing the data for the model.

### Define a column schema so we can check data is as expected

```{r}
#| label: define expected schemas

schema_vesselhistory <- col_schema(
                                  vessel_id = "integer",
                                  vessel = "character",
                                  departing = "character",
                                  arriving = "character",
                                  scheduled_depart = "character",
                                  actual_depart = "character",
                                  est_arrival = "character",
                                  date = "character"
                               )


schema_weather <- col_schema(
                            terminal = "character",
                            lat = "numeric",
                            long = "numeric",
                            time = "character", 
                            precipitation = "numeric",
                            weather_code = "integer", 
                            cloud_cover_low = "integer",
                            wind_speed_10m = "numeric",
                            wind_gusts_10m = "numeric"
                            )

```

### Validate the raw data column schemas

If either raw data schema fail validation, it will generate a stop notice and prevent downstream processing.

```{r}
#| label: data schema validations

# These are our data set integrity validations. All of these trigger a stop notice under fail conditions.
# Troubleshooting: if either of these fail, look at the x_list$col_types and $col_names to see the discrepancy

# validate integrity of vessel history data frame
vesselhistory_df_integrity_agent <- 
  create_agent(vesselhistory_raw, label = "Inital validation of the vessel history set to confirm overall schema and size. If there are issues with this validation, further processing stops and an alert is triggered.") |> 
  # verify column schema 
  col_schema_match(schema_vesselhistory, 
                   label = "Is the column schema as expected?") |> 
  #Check that expected columns exist. We make a table in the preconditions using a table transform that is made up of the column names of our inspections table. Then compare those values to the set of schema_inspection names.
  col_vals_in_set(columns = value, 
                  set = names(schema_vesselhistory), 
                  preconditions = ~. %>% tt_tbl_colnames, 
                  label = "Are the expected columns in the data set?") |> 
  # verify there are A LOT of rows of data to be sure import didn't mess up. 
  col_vals_gte(columns = n, 
               value = 10000L, # an arbitrary high-ish number
               preconditions = ~. %>% tally,
               label = "Are there more than 10k rows in the data?") |>
  interrogate()

vesselhistory_df_integrity_agent

# validate integrity of weather data frame
weather_df_integrity_agent <- 
  create_agent(weather_terminal_history_raw, label = "Inital validation of the station weather history data to confirm overall schema and size. If there are issues with this validation, further processing stops and an alert is triggered.") |> 
  # verify column schema 
  # troubleshooting, if this fails, look at the x_list$col_types and $col_names to see the discrepancy
  col_schema_match(schema_weather, 
                   label = "Is the column schema as expected?") |> 
  #Check that expected columns exist. We make a table in the preconditions using a table transform that is made up of the column names of our inspections table. Then compare those values to the set of schema_inspection names.
  col_vals_in_set(columns = value, 
                  set = names(schema_weather), 
                  preconditions = ~. %>% tt_tbl_colnames, 
                  label = "Are the expected columns in the data set?") |> 
  # verify there are A LOT of rows of data to be sure import didn't mess up. 
  col_vals_gte(columns = n, 
               value = (
                 # an arbitrary high-ish number, depending on the environment
                 if(config::is_active("default")){
                   10L} else {
                     100000L
                   }), 
               preconditions = ~. %>% tally,
               label = "Are there more than 100k rows in the data?") |>
  interrogate()
weather_df_integrity_agent
```

### Set `condition <- 1` or `stop_alert` if there are any issues

Condition 1 will result in an alert email indicating there was a data integrity issue. 
`stop_alert` will prevent future code chunks from rendering, including preventing writes to the database

```{r}
#| label: set condition or stop alert

# condition<-1 will be set if CONDITION_OVERRIDE is set to 1, or if either data frame integrity validations failed. This specifies which email will be sent.
if(any(Sys.getenv("CONDITION_OVERRIDE") == 1,
       !all_passed(vesselhistory_df_integrity_agent),
       !all_passed(weather_df_integrity_agent))){
  condition <- 1
}

# set a boolean that will stop additional data processing if there are any data integrity issues
stop_alert <- any((if(exists("condition")){condition == 1}), Sys.getenv("CONDITION_OVERRIDE") == 1)

```

## Task 5 - Clean and transform data

üîÑ Task

As long as the raw data integrity validations passed, clean and transform the data to prepare it for additional validation and modeling. Cleaning will include:

-   convert dates into a usable format
-   convert terminal names and vessel names to lowercase
-   bring terminal names into agreement across data frames
-   calculate departure delay - create route-pairs for grouping related records
-   join the weather data with the sailing history, which will become our training data.

Notice that in the quarto code chunks, we have set `#| eval: !expr 'stop_alert != TRUE'` to prevent the code from running during rendering if there is a data integrity issue. This will save computation time by not bothering to render code chunks with questionable data.

### Clean data

Data cleaning steps are extraneous to the learning objectives of the Workshop. To simply this document, cleaning steps have been wrapped in a function in the `ferryfairy` package.
.
```{r}
#| label: Clean data sets
#| eval: !expr 'stop_alert != TRUE'

weather_terminal_history <- clean_weather_terminal(weather_terminal_history_raw)
weather_terminal_history

vesselinfo <- clean_vesselinfo(vesselinfo_raw)
vesselinfo

vesselhistory <- clean_vesselhistory(vesselhistory_raw)
vesselhistory

```


### Join weather data with vessel history

This data will be what we use for the model. We'll join the weather data to the vessel history data based on the terminal and the date and time. The weather data is reported on the hour, so we will create a column in the vesselhistory rounding the scheduled departure time to the closest hour.

```{r}
#| label: Join weather data to vesselhistory
#| eval: !expr 'stop_alert != TRUE'

vesselhistory_w_weather <- vesselhistory |> 
  # round the scheduled departure to the closest hour to align with weather data
  mutate(closest_hour = round_date(scheduled_depart, "hour")) |> 
  # join the weather data to the vessel history data based on terminal and time
  left_join(weather_terminal_history, by = c("departing" = "terminal", "closest_hour" = "time")) 

vesselhistory_w_weather
```

## Task 6 - Validate the model data

üîÑ Task

Use `pointblank` to create a validation agent and interrogate.

Sometimes it's okay to have records fail a validation. Perhaps a value is out of range or there was an error in data entry. A reasonable number of failing records may be expected, however, if a large amount of records are failing validation, this could be an indicator of larger data quality problems.

We will set "action levels" for each validation step in this agent. Exceeding the action level threshold will set a flag for that step. A validation step can have one or more ation levels for "notify," "warn," or "stop." We will then use the presence of this warning flag to conditionally send an email alert if a larger fraction of our data failed validation than we expected.

### Validate to remove errant data before modeling

```{r}
#| label: Validate data to be used for the model
#| eval: !expr 'stop_alert != TRUE'

main_agent <- create_agent(vesselhistory_w_weather) |> 
  # all records are distinct
  rows_distinct() |> 
  # sailing date is prior to today
  col_vals_lte(columns = date, today(),
               label = "Sailing date prior to today",
               actions = action_levels(warn_at = 0.01)) |> 
  # vessel_name is one known from vesseldata
  col_vals_in_set(columns =  vessel, 
                  set = vesselinfo$vessel_name, 
                  label = "Vessel name is known",
                  actions = action_levels(warn_at = 0.01)) |>
  # a departure and arrival must be specified
  col_vals_not_null(columns = c(departing, arriving),
                    actions = action_levels(warn_at = 0.05)) |> 
  # departing and arriving terminals are known
  col_vals_in_set(columns = c(departing, arriving), 
                  set = c(unique(weather_terminal_history$terminal),NA),
                  label = "Terminal name is known",
                  actions = action_levels(warn_at = 0.1)) |> 
  # calculated delay is not null
  col_vals_not_null(columns = delay) |> 
  # a departure more than 5 minutes early is likely bad data
  col_vals_gte(columns = delay, -5,
               label = "Departed no more than 5 minutes early",
               actions = action_levels(warn_at = 0.01)) |>
  # a departure more than 5 minutes early is likely bad data
  col_vals_gte(columns = delay, -5,
               label = "Departed no more than 5 minutes early",
               actions = action_levels(warn_at = 0.01)) |> 
  # weather code is valid
  col_vals_between(columns = weather_code, 0, 99, na_pass = TRUE,
                   actions = action_levels(warn_at = 0.01)) |> 
  # cloud_cover_low is valid
  col_vals_between(columns = cloud_cover_low, 0, 100, na_pass = TRUE,
                   actions = action_levels(warn_at = 0.01)) |> 
  interrogate()

main_agent

x_list <- get_agent_x_list(main_agent)
```

### Set `condition` to determine which email to send

Condition 2 will result in an alert email indicating that a concerning level of records failed validation, but downstream processing still proceeded.
Condition 3 will result in an email indicating that all looks good

```{r}
#| label: set condition 2 or 3

# condition<-2 will be set if it is in override or if any warnings are set, otherwise condition<-3

if(Sys.getenv("CONDITION_OVERRIDE") %in% c(2,3)){
  condition <- Sys.getenv("CONDITION_OVERRIDE")
}else if(any(x_list$warn)){
  condition <- 2
}else condition <- 3

```

## Task 7 - Remove failed records from dataset

üîÑ Task

Pointblank has identified all of the rows of `vesselhistory_w_weather` that passed and failed validation. Now remove those that failed so the data that is passed downstream to our modeling step is squeaky clean.

```{r}
#| label: sunder data
#| eval: !expr 'stop_alert != TRUE'

modeldata_validated <- get_sundered_data(main_agent, type = "pass")
modeldata_fail_validation <- get_sundered_data(main_agent, type = "fail")

```

## Task 8 - Write cleaned and validated data to database

üîÑ Task

Write cleaned data to database

```{r}
#| label: write validated data to database
#| eval: false
##| eval: !expr 'stop_alert != TRUE & !Sys.getenv("CONDITION_OVERRIDE") %in% c(1:3)'

df_suffix <- config::get("suffix")

my_df_name <- paste0("modeldata_validated_", df_suffix)

# Insert start time stamp
start_time <- Sys.time()

DBI::dbWriteTable(conn = con, # the connection
                  name = my_df_name, # the name of the table you will create in the DB
                  value = modeldata_validated,
                  append = TRUE)


# Insert end time stamp
end_time <- Sys.time()
duration <- end_time - start_time


print(glue::glue("‚ÑπÔ∏è Info: Writing {my_df_name} to database took",  round(duration[[1]], 2),  units(duration)))

```

```{r}
#| label: write data
#| eval: false 
##| eval: !expr 'stop_alert != TRUE & !Sys.getenv("CONDITION_OVERRIDE") %in% c(1:3)'

board <- board_connect()

pin_write(board, vesseldata,
          title="Cleaned and validated `vesselverbose` data from WSDOT",
          description="from `Ferries/API/Vessels/rest/vesselverbose`")

pin_write(board, vesselhistory,
          title="Cleaned and validated `vesselhistory` data from WSDOT",
          description="from `Ferries/API/Vessels/rest/vesselhistory`")


pin_write(board, weather_terminal_history,
          type = "csv",
          title = "Cleaned and validated historical weather data at ferry terminals",
          description = "From `open-meteo.com`, dates 2023-05-31 to 2024-05-31")

pin_write(board, vesselhistory_w_weather,
          type = "csv",
          title = "Vessel sailing history with weather data")

pin_write(board, modeldata_validated,
          type = "csv",
          title = "Cleaned and validated vessel sailing history with weather data for model consumption")
```

## Task 9 - Send Conditional Email 

üîÑ Task

- for the Workshop, change the value of `CONDITION_OVERRIDE` in the `.Renviron` file to 1, 2, or 3 to preview the conditional responses. 
- Be certain to restart your R session after changing the `.Renviron` file, then "Render" this document to see the results.
- Look in the folder `email-preview` to see the HTML email preview.

Below is how we generate the emails.

We have three scenarios:

1.  `condition <- 1`: the size and shape of the data is not as expected; something is wrong with the input data so the processing of data is stopped and no production data is updated
2. `condition <- 2`: data validation complete but had warnings
3.  `condition <- 3`: no issues with validation

We will use a feature of Quarto that allows yaml to be written at any point in the document. With this, we will define which conditional email should be sent as metadata. Then the subject and body of the email will be selected using Quarto's ability to include or exclude content based on a metadata value.

### Write condition to metadata

Metadata to be written will be: `use_condition_{condition}_email: true`

#### define a helper function to more cleanly write metadata

```{r}
#| label: metadata helper

write_meta <- function(meta) {
  handlers <- list(logical = function(x) {
        value <- ifelse(x, "true", "false")
        structure(value, class = "verbatim")
    })
  res <- yaml::as.yaml(meta, handlers = handlers)
  knitr::asis_output(paste0("---\n", res, "---\n"))
}
```

#### write metadata

```{r}
#| label: write metadata
metadata_key <- glue::glue("use_condition_{condition}_email")

metadata_list <- list()
metadata_list[[metadata_key]] <- TRUE

write_meta(metadata_list)

```

### Define the email

::::::::: email
:::: {.content-visible when-meta="use_condition_1_email"}
::: subject
‚ö†Ô∏èÔ∏è Ferry Project: Data integrity issue
:::

## ‚ö†Ô∏è There was a data integrity issue with the project data on `{r} today()`

The data integrity validations check that the raw vessel history and terminal weather data have the expected column names and schema, and a minimum number of rows are present.

The validations for `{r} today()` **failed**, indicating a data integrity issue.

Further processing of the data did not take place. **Downstream content and artifacts have not been updated.**

Please review the incoming raw data to diagnose the issue.

The results of the data frame validation are shown below:

```{r}
#| echo: false
#| eval: !expr 'condition == 1'

vesselhistory_df_integrity_agent

weather_df_integrity_agent

```
::::

:::: {.content-visible when-meta="use_condition_2_email"}
::: subject
‚ÑπÔ∏è Ferry Project: Data updated with warnings
:::

## ‚ÑπÔ∏è Ferry data validation complete for `{r} today()` with warnings

The ferry data for modeling has been cleaned, validated, and written, but there were warnings set because the threshold for failure was exceeded.

### Validation failures

The table below summarizes the validation step(s) that triggered warnings.

```{r}
#| label: get failing validations details
#| eval: !expr 'condition == 2'
#| echo: false

step <- x_list$i[which(x_list$warn)]
desc <- x_list$briefs[which(x_list$warn)]
fails <- x_list$f_failed[which(x_list$warn)]
threshold <- purrr::map(step, ~{x_list$validation_set$actions[[.x]]$warn_fraction}) |> unlist()

warnings_table <- data.frame(step, desc,threshold,fails) |> gt() |> cols_label(step="Validation Step",desc="Description",fails="Fraction Failed", threshold="Threshold") |> fmt_number(columns = c(fails, threshold),decimal = 2)

warnings_table |> as_raw_html() 
```

Review the associated extract files to see the records that failed validation.

```{r}
#| label: get extracts
#| eval: !expr 'condition == 2'
#| echo: false


failures <- purrr::map(step, ~{get_data_extracts(main_agent, .x)})

purrr::walk2(failures, step, ~{write_csv(.x, file = glue("extracts_step_{.y}.csv"))})

filenames_yaml <- glue(" - extracts_step_{step}.csv") |> str_c(collapse = "\n")

```

```{r}
#| label: add email attachment metadata
#| eval: !expr 'condition == 2'
#| output: asis
#| echo: false

cat(
  "---",
  paste0("email-attachments: \n", filenames_yaml),
  "---",
  sep = "\n"
)


```

### Summary of data written

The table below summarizes the data written.

```{r}
#| label: data summary table
#| eval: !expr 'condition == 2'
#| echo: false

summary_table

```
::::

:::: {.content-visible when-meta="use_condition_3_email"}
::: subject
‚úÖ Ferry Project: Data updated
:::

## ‚õ¥Ô∏è Ferry data validation complete for `{r} today()`

The ferry data for modeling has been cleaned, validated, andwritten to the database.

A summary of the data is shown below.

```{r}
#| label: summary of data
#| eval: !expr 'condition == 3'
#| echo: false


summary_table 


```
::::
:::::::::

## Logging information

Report run `{r} today()`

```{r}
#| label: logging
#| echo: false
#| output: asis



if (condition == 1){
print(glue("Data integrity validation failed. Data processing for the model training did not proceed. An email notification of the failure was sent."))
}

if (condition == 2){

print(glue("Vessel history and weather data was validated and sundered, however a warning was triggered due to one or more validation steps exceeding the threshold for allowed failures.

Records removed that failed validation: {nrow(modeldata_fail_validation)}

Records written to database: {nrow(modeldata_validated)}

Warnings triggered for validation step(s) listed below:"))

warnings_table

}

if (condition == 3){
glue("Vessel history and weather data was validated and sundered.

Records removed that failed validation: {nrow(modeldata_fail_validation)}

Records written to database: {nrow(modeldata_validated)}")

}



```